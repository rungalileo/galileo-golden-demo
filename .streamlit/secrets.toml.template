# API Keys
openai_api_key = ""
galileo_api_key = ""

# Galileo Configuration
galileo_project = ""
galileo_log_stream = ""
galileo_console_url = "https://app.galileo.ai"

# Pinecone Configuration
# Each project has its own API key, need both to create vector dbs for both local and hosted demos
pinecone_api_key_local = ""    # For galileo-demo-local project
pinecone_api_key_hosted = ""   # For galileo-demo-hosted project

# AWS Configuration
aws_access_key_id = ""
aws_secret_access_key = ""
aws_default_region = "us-east-1"
bedrock_model_arn = ""
BEDROCK_MODEL_ID = ""
BEDROCK_JUDGE_MODEL_ID = ""  # Model ID for custom metric evaluation (e.g., "anthropic.claude-3-5-haiku-20241022-v1:0" or "Anthropic - Claude 3.5 Haiku (Bedrock)")

# Environment Configuration
# Set to "local" for local development, "hosted" for production
environment = "local"

# Used to authorize users for deleting experiments
admin_key = ""

# OpenTelemetry Configuration
# Service name for tracing
otel_service_name = "galileo-golden-demo"

# OTLP endpoint for exporting traces (optional)
# Example: "http://localhost:4318/v1/traces" or "https://your-otel-collector.com/v1/traces"
# For Galileo: "https://api.galileo.ai/otel/traces"
otel_exporter_otlp_endpoint = ""

# OTLP headers for authentication (optional)
# Galileo format: "key=value,key2=value2" (comma-separated with equals)
# For Galileo, headers are auto-configured from your Galileo API key, project, and log stream
# Manual format: "Galileo-API-Key=your-key,project=your-project,logstream=your-log-stream"
# Per Galileo docs: https://v2docs.galileo.ai/how-to-guides/third-party-integrations/otel
otel_exporter_otlp_traces_headers = ""

# Enable console exporter for debugging (set to "true" to enable)
otel_console_exporter = "false"

# Enable OpenInference instrumentations for LangChain (recommended: "true")
otel_enable_openinference = "true"
